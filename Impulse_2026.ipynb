{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5PbW3Xvrc5I"
      },
      "source": [
        "# EchoFind – Self-Supervised Audio Representation Learning\n",
        "Impulse 2026 Submission (Cleaned Pipeline)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 1: Input Pipeline & Preprocessing (Steps 1–4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sandeep kumar\\impulse_env\\Scripts\\python.exe\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (2.3.5)\n",
            "Requirement already satisfied: pandas in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (3.0.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (1.8.0)\n",
            "Requirement already satisfied: matplotlib in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (3.10.8)\n",
            "Requirement already satisfied: tqdm in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (4.67.2)\n",
            "Requirement already satisfied: torch in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (2.10.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from librosa) (0.63.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from librosa) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.0 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from librosa) (1.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from librosa) (5.2.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from librosa) (1.9.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from matplotlib) (12.1.0)\n",
            "Requirement already satisfied: pyparsing>=3 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: colorama in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from tqdm) (0.4.6)\n",
            "Requirement already satisfied: filelock in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from torch) (2026.1.0)\n",
            "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from numba>=0.51.0->librosa) (0.46.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from pooch>=1.1->librosa) (4.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from pooch>=1.1->librosa) (2.32.5)\n",
            "Requirement already satisfied: six>=1.5 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2026.1.4)\n",
            "Requirement already satisfied: cffi>=1.0 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: pycparser in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\Users\\Sandeep kumar\\impulse_env\\Lib\\site-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install librosa numpy pandas scikit-learn matplotlib tqdm torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kZ3iN6Mhx72",
        "outputId": "9d03e8e4-b0fc-4976-a853-8a5bbf9ed811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "print(\"Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiVTnFM0ie5d",
        "outputId": "21c912f5-ef72-44f9-88ed-6719ed79e4b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exists: True\n",
            "Sample folders: ['000', '001', '002', '003', '004']\n"
          ]
        }
      ],
      "source": [
        "SAFE_BASE = r\"H:\\My Drive\\Impulse2026_SSL\\data\"\n",
        "DATA_DIR = SAFE_BASE\n",
        "SAFE_AUDIO_PATH = r\"H:\\My Drive\\Impulse2026_SSL\\data\\fma_small\\fma_small\"\n",
        "\n",
        "print(\"Exists:\", os.path.exists(SAFE_AUDIO_PATH))\n",
        "print(\"Sample folders:\", sorted(os.listdir(SAFE_AUDIO_PATH))[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgkGOhRKjMmg",
        "outputId": "19c9bf86-0a3e-4ce1-8d79-5469bc6b4141"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LOCKED audio root: H:\\My Drive\\Impulse2026_SSL\\data\\fma_small\\fma_small\n"
          ]
        }
      ],
      "source": [
        "audio_root = SAFE_AUDIO_PATH\n",
        "print(\"LOCKED audio root:\", audio_root)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 2: Self-Supervised Representation Learning (Steps 5–12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoYXPTgkj8dv"
      },
      "source": [
        "# **Step-5 MFCC**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MFCCs are extracted per audio clip using librosa. In practice, MFCCs are computed inside the batch embedding pipeline (see extract_embedding). This section illustrates the concept on a single sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd5vnn_TkZo_"
      },
      "source": [
        "# **STEP 6 — Convert variable-length MFCC → fixed-size embedding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MFCC features are computed as a time–frequency representation, where the number of time frames depends on the duration of the audio signal.\n",
        "As a result, raw MFCC matrices have variable temporal length across different audio clips, which makes them unsuitable for direct use in neural networks that expect fixed-size inputs.\n",
        "\n",
        "To address this, a statistical pooling strategy is applied:\n",
        "\n",
        "Mean pooling across the time axis captures the average spectral characteristics of the audio.\n",
        "\n",
        "Standard deviation pooling captures temporal variability and dynamics.\n",
        "\n",
        "By concatenating the mean and standard deviation vectors, each audio clip is transformed into a fixed-dimensional embedding independent of its duration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJWaso_flWNo"
      },
      "source": [
        "# **STEP 7 — Apply this embedding extraction to MULTIPLE audio files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BQGA9X38lcKk"
      },
      "outputs": [],
      "source": [
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def extract_embedding(audio_path, sr=22050, n_mfcc=40):\n",
        "    signal, _ = librosa.load(audio_path, sr=sr)\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "    mfcc_mean = np.mean(mfcc, axis=1)\n",
        "    mfcc_std = np.std(mfcc, axis=1)\n",
        "\n",
        "    embedding = np.concatenate([mfcc_mean, mfcc_std])\n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN4N52H6lzPl",
        "outputId": "a6f2d8b4-9e2e-4a9e-9e4a-cf88af532825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total audio files found: 8000\n",
            "Sample file: H:\\My Drive\\Impulse2026_SSL\\data\\fma_small\\fma_small\\000\\000002.mp3\n"
          ]
        }
      ],
      "source": [
        "audio_files = []\n",
        "\n",
        "for folder in sorted(os.listdir(SAFE_AUDIO_PATH)):\n",
        "    folder_path = os.path.join(SAFE_AUDIO_PATH, folder)\n",
        "\n",
        "    if not os.path.isdir(folder_path):\n",
        "        continue\n",
        "\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith(\".mp3\"):\n",
        "            audio_files.append(os.path.join(folder_path, file))\n",
        "\n",
        "print(\"Total audio files found:\", len(audio_files))\n",
        "print(\"Sample file:\", audio_files[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cPKC3Vvpl5HL"
      },
      "outputs": [],
      "source": [
        "# SUBSAMPLING FOR SPEED \n",
        "\n",
        "sample_files = audio_files[:799]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFdcrgWumTQP",
        "outputId": "db9f041b-1d62-4a62-9c78-c6e9ba4b16a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting embeddings: 100%|██████████| 799/799 [07:18<00:00,  1.82file/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding matrix shape: (799, 80)\n",
            "Mean: 4.0233145\n",
            "Std: 25.741259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "embeddings = []\n",
        "\n",
        "for path in tqdm(sample_files, desc=\"Extracting embeddings\", unit=\"file\"):\n",
        "    emb = extract_embedding(path)\n",
        "    embeddings.append(emb)\n",
        "\n",
        "X = np.array(embeddings)\n",
        "print(\"Embedding matrix shape:\", X.shape)\n",
        "print(\"Mean:\", X.mean())\n",
        "print(\"Std:\", X.std())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1LJtrZPqzP6"
      },
      "source": [
        "# **STEP 8 — Normalize the embedding matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42b5l0ZjrBVC",
        "outputId": "681b9bc0-1ff0-466a-cccc-d40b1d963a8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (799, 80)\n",
            "Mean: 9.548679e-09\n",
            "Std: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "embedding_matrix = X   # LOCK THIS\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_norm = scaler.fit_transform(embedding_matrix)\n",
        "\n",
        "print(\"Shape:\", X_norm.shape)\n",
        "print(\"Mean:\", np.mean(X_norm))\n",
        "print(\"Std:\", np.std(X_norm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs3hV96etrbe"
      },
      "source": [
        "# **STEP 9 — SSL AUGMENTATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5eaU1Go8tvzC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def augment_embedding(x, noise_std=0.1, drop_prob=0.07):\n",
        "    x_aug = x.copy()\n",
        "    x_aug += np.random.normal(0, noise_std, size=x.shape)\n",
        "    mask = np.random.rand(*x.shape) > drop_prob\n",
        "    x_aug *= mask\n",
        "    return x_aug\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chvN9E6UwM-A"
      },
      "source": [
        "# **STEP 10 — Define the Neural Encoder (MLP)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sandeep kumar\\impulse_env\\Scripts\\python.exe\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "cZT6OojIwa-d"
      },
      "outputs": [],
      "source": [
        "class AudioEncoder(nn.Module):\n",
        "    def __init__(self, input_dim=80, hidden_dim=128, output_dim=32):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.net(x)\n",
        "        z = F.normalize(z, dim=1)  # critical for cosine-based SSL\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5qy15upwh7D",
        "outputId": "a097e0fc-8434-4606-bac4-8017e044e646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AudioEncoder(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=80, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=32, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AudioEncoder().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1KzA2JnwyrM"
      },
      "source": [
        "# **STEP 11 — Define the Contrastive Loss (SSL Learning Signal)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Cj4oNH5xw1D-"
      },
      "outputs": [],
      "source": [
        "def contrastive_loss(z1, z2, temperature=0.1):\n",
        "    \"\"\"\n",
        "    z1, z2: (batch_size, embedding_dim)\n",
        "    \"\"\"\n",
        "    batch_size = z1.size(0)\n",
        "\n",
        "    # Similarity matrix\n",
        "    sim_matrix = torch.matmul(z1, z2.T) / temperature\n",
        "\n",
        "    # Positive pairs are on the diagonal\n",
        "    labels = torch.arange(batch_size).to(z1.device)\n",
        "\n",
        "    loss = F.cross_entropy(sim_matrix, labels)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krfvQwHLx3AX"
      },
      "source": [
        "# **STEP 12 — Full SSL Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "t2Dv6lj1x6RO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SSLAudioDataset(Dataset):\n",
        "    def __init__(self, X):\n",
        "        self.X = X\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx]\n",
        "        x1 = augment_embedding(x)\n",
        "        x2 = augment_embedding(x)\n",
        "        return (\n",
        "            torch.tensor(x1, dtype=torch.float32),\n",
        "            torch.tensor(x2, dtype=torch.float32)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frb2sqWxzrog",
        "outputId": "dc9037fc-c98b-4977-de24-d950ebf61001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batches per epoch: 24\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset = SSLAudioDataset(X_norm)\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "print(\"Batches per epoch:\", len(dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TZ_wGJMEz3Ha"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndIGq9xCz7v6",
        "outputId": "db75daed-c5b0-4a22-8d6e-c7331d6f088e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/15] - Avg Loss: 0.2479\n",
            "Epoch [2/15] - Avg Loss: 0.0865\n",
            "Epoch [3/15] - Avg Loss: 0.0742\n",
            "Epoch [4/15] - Avg Loss: 0.0592\n",
            "Epoch [5/15] - Avg Loss: 0.0558\n",
            "Epoch [6/15] - Avg Loss: 0.0629\n",
            "Epoch [7/15] - Avg Loss: 0.0479\n",
            "Epoch [8/15] - Avg Loss: 0.0452\n",
            "Epoch [9/15] - Avg Loss: 0.0483\n",
            "Epoch [10/15] - Avg Loss: 0.0420\n",
            "Epoch [11/15] - Avg Loss: 0.0416\n",
            "Epoch [12/15] - Avg Loss: 0.0383\n",
            "Epoch [13/15] - Avg Loss: 0.0434\n",
            "Epoch [14/15] - Avg Loss: 0.0364\n",
            "Epoch [15/15] - Avg Loss: 0.0330\n"
          ]
        }
      ],
      "source": [
        "epochs = 15\n",
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x1, x2 in dataloader:\n",
        "        x1 = x1.to(device)\n",
        "        x2 = x2.to(device)\n",
        "\n",
        "        z1 = model(x1)\n",
        "        z2 = model(x2)\n",
        "\n",
        "        loss = contrastive_loss(z1, z2)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] - Avg Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lyFcx646Hu2M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# CHECKPOINT SAVE — trained encoder (path is environment-specific)\n",
        "# CHECKPOINT 1 — end of Phase 2\n",
        "output_dir = \"/content/drive/MyDrive/Impulse2026/weights\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "torch.save(\n",
        "    model.state_dict(),\n",
        "    os.path.join(output_dir, \"encoder_final.pth\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M3ShOxkJ2H-"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 3: Retrieval / Shazam Test (Steps 12.5–14)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag_h9Nj6Ii6a"
      },
      "source": [
        "# **STEP 12.5 — Phase 3: Retrieval (Shazam Test)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeO8nfepIpYS",
        "outputId": "c454f35d-d52e-4434-ce1e-aff1be42e5cc"
      },
      "outputs": [],
      "source": [
        "#Loaded Trained Encoder\n",
        "model.load_state_dict(torch.load(\n",
        "    \"/content/drive/MyDrive/Impulse2026/weights/encoder_final.pth\"\n",
        "))\n",
        "model.eval()\n",
        "\n",
        "def get_audio_model_embedding(audio_path, model, scaler_obj, device_obj):\n",
        "    # 1. Extract raw MFCC embedding\n",
        "    raw_embedding = extract_embedding(audio_path)\n",
        "\n",
        "    # 2. Normalize using the trained scaler\n",
        "    normalized_embedding = scaler_obj.transform(raw_embedding.reshape(1, -1))\n",
        "\n",
        "    # 3. Pass through the trained model\n",
        "    model.eval() # Ensure model is in evaluation mode\n",
        "    with torch.no_grad():\n",
        "        tensor_embedding = torch.tensor(normalized_embedding, dtype=torch.float32).to(device_obj)\n",
        "        final_embedding = model(tensor_embedding).cpu().numpy().flatten()\n",
        "    return final_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkEIVcPVJmml",
        "outputId": "808ce2a4-00c8-4125-b038-5d63101a599b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Building model embedding database: 100%|██████████| 700/700 [07:26<00:00,  1.57it/s]\n"
          ]
        }
      ],
      "source": [
        "# build database\n",
        "database_model_embeddings = {}\n",
        "model.eval()\n",
        "\n",
        "audio_files_phase3 = audio_files[:700]\n",
        "\n",
        "\n",
        "for path in tqdm(audio_files_phase3, desc=\"Building model embedding database\"):\n",
        "    track_id = os.path.basename(path)\n",
        "    model_emb = get_audio_model_embedding(path, model, scaler, device)\n",
        "    database_model_embeddings[track_id] = model_emb\n",
        "\n",
        "database = database_model_embeddings\n",
        "import os\n",
        "\n",
        "save_dir = r\"H:/My Drive/Impulse2026_SSL/weights\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "torch.save(database, os.path.join(save_dir, \"database_embeddings.pt\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "jalrRl-fWhAv"
      },
      "outputs": [],
      "source": [
        "#retrival Function\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def predict_track(query_audio_path, model, database_embeddings_dict):\n",
        "\n",
        "    query_model_embedding = get_audio_model_embedding(query_audio_path, model, scaler, device)\n",
        "    best_id, best_score = None, -1.0\n",
        "\n",
        "    for track_id, db_model_embedding in database_embeddings_dict.items():\n",
        "\n",
        "        score = cosine_similarity(query_model_embedding.reshape(1, -1), db_model_embedding.reshape(1, -1))[0][0]\n",
        "        if score > best_score:\n",
        "            best_score, best_id = score, track_id\n",
        "\n",
        "    return best_id, best_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76qn8LKf0IPu"
      },
      "source": [
        "# **STEP 13 — Generate FINAL Learned Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "HqBETiNr0K2y"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLv3JaJ20QYW",
        "outputId": "1a615446-bbb1-4fa2-afde-e7ef562850a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final embedding matrix shape: (799, 32)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "final_embeddings = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(X_norm), 32):\n",
        "        batch = torch.tensor(\n",
        "            X_norm[i:i+32],\n",
        "            dtype=torch.float32\n",
        "        ).to(device)\n",
        "\n",
        "        z = model(batch)\n",
        "        final_embeddings.append(z.cpu().numpy())\n",
        "\n",
        "final_embeddings = np.vstack(final_embeddings)\n",
        "\n",
        "print(\"Final embedding matrix shape:\", final_embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqOPp9tY13Hc"
      },
      "source": [
        "# **STEP - 14 OUTPUT CSV- download**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "audio_ids = [os.path.basename(p) for p in audio_files_phase3]\n",
        "final_embeddings = final_embeddings[:len(audio_ids)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5Uoz2uG2r8Z",
        "outputId": "2f0c31e6-6050-4b1b-8936-25fca18813d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "outputs.csv saved with shape: (700, 33)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "df = pd.DataFrame(final_embeddings)\n",
        "df.insert(0, \"audio_id\", audio_ids)\n",
        "df.to_csv(\"outputs.csv\", index=False)\n",
        "print(\"outputs.csv saved with shape:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "Dk74NrUa2swf",
        "outputId": "b74b1157-acc2-46e5-a6f4-9a2441c575b5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_id</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000002.mp3</td>\n",
              "      <td>-0.249946</td>\n",
              "      <td>0.132043</td>\n",
              "      <td>0.018047</td>\n",
              "      <td>-0.077988</td>\n",
              "      <td>0.193615</td>\n",
              "      <td>0.088332</td>\n",
              "      <td>-0.407737</td>\n",
              "      <td>-0.087728</td>\n",
              "      <td>0.091752</td>\n",
              "      <td>...</td>\n",
              "      <td>0.097703</td>\n",
              "      <td>0.071560</td>\n",
              "      <td>0.114588</td>\n",
              "      <td>-0.055781</td>\n",
              "      <td>-0.269220</td>\n",
              "      <td>0.191771</td>\n",
              "      <td>-0.094684</td>\n",
              "      <td>0.178524</td>\n",
              "      <td>-0.136390</td>\n",
              "      <td>-0.050486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000005.mp3</td>\n",
              "      <td>0.330494</td>\n",
              "      <td>0.138537</td>\n",
              "      <td>-0.091513</td>\n",
              "      <td>0.015584</td>\n",
              "      <td>0.159510</td>\n",
              "      <td>-0.074857</td>\n",
              "      <td>-0.215261</td>\n",
              "      <td>-0.326665</td>\n",
              "      <td>0.258441</td>\n",
              "      <td>...</td>\n",
              "      <td>0.155142</td>\n",
              "      <td>-0.102439</td>\n",
              "      <td>-0.397522</td>\n",
              "      <td>0.243152</td>\n",
              "      <td>-0.167941</td>\n",
              "      <td>-0.025723</td>\n",
              "      <td>0.069258</td>\n",
              "      <td>-0.024735</td>\n",
              "      <td>0.018322</td>\n",
              "      <td>-0.180069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000010.mp3</td>\n",
              "      <td>-0.032046</td>\n",
              "      <td>0.078719</td>\n",
              "      <td>-0.171027</td>\n",
              "      <td>0.016308</td>\n",
              "      <td>-0.055242</td>\n",
              "      <td>0.148234</td>\n",
              "      <td>-0.271889</td>\n",
              "      <td>0.058019</td>\n",
              "      <td>-0.155045</td>\n",
              "      <td>...</td>\n",
              "      <td>0.131858</td>\n",
              "      <td>0.011409</td>\n",
              "      <td>-0.455784</td>\n",
              "      <td>0.259496</td>\n",
              "      <td>-0.146869</td>\n",
              "      <td>0.145466</td>\n",
              "      <td>0.276061</td>\n",
              "      <td>0.004051</td>\n",
              "      <td>-0.088571</td>\n",
              "      <td>-0.169602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000140.mp3</td>\n",
              "      <td>-0.133465</td>\n",
              "      <td>0.104155</td>\n",
              "      <td>0.201438</td>\n",
              "      <td>-0.010338</td>\n",
              "      <td>0.147765</td>\n",
              "      <td>0.120849</td>\n",
              "      <td>0.115359</td>\n",
              "      <td>-0.056955</td>\n",
              "      <td>0.055758</td>\n",
              "      <td>...</td>\n",
              "      <td>0.202641</td>\n",
              "      <td>-0.280212</td>\n",
              "      <td>-0.013400</td>\n",
              "      <td>-0.075353</td>\n",
              "      <td>-0.076547</td>\n",
              "      <td>0.002127</td>\n",
              "      <td>0.124289</td>\n",
              "      <td>0.016724</td>\n",
              "      <td>0.285925</td>\n",
              "      <td>0.128968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000141.mp3</td>\n",
              "      <td>-0.071291</td>\n",
              "      <td>-0.151354</td>\n",
              "      <td>-0.089084</td>\n",
              "      <td>-0.290726</td>\n",
              "      <td>0.107025</td>\n",
              "      <td>-0.064288</td>\n",
              "      <td>-0.259864</td>\n",
              "      <td>0.326355</td>\n",
              "      <td>0.022939</td>\n",
              "      <td>...</td>\n",
              "      <td>0.216391</td>\n",
              "      <td>0.242005</td>\n",
              "      <td>-0.092364</td>\n",
              "      <td>0.298605</td>\n",
              "      <td>-0.110453</td>\n",
              "      <td>0.108763</td>\n",
              "      <td>0.228472</td>\n",
              "      <td>-0.106571</td>\n",
              "      <td>0.071141</td>\n",
              "      <td>-0.012153</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     audio_id         0         1         2         3         4         5  \\\n",
              "0  000002.mp3 -0.249946  0.132043  0.018047 -0.077988  0.193615  0.088332   \n",
              "1  000005.mp3  0.330494  0.138537 -0.091513  0.015584  0.159510 -0.074857   \n",
              "2  000010.mp3 -0.032046  0.078719 -0.171027  0.016308 -0.055242  0.148234   \n",
              "3  000140.mp3 -0.133465  0.104155  0.201438 -0.010338  0.147765  0.120849   \n",
              "4  000141.mp3 -0.071291 -0.151354 -0.089084 -0.290726  0.107025 -0.064288   \n",
              "\n",
              "          6         7         8  ...        22        23        24        25  \\\n",
              "0 -0.407737 -0.087728  0.091752  ...  0.097703  0.071560  0.114588 -0.055781   \n",
              "1 -0.215261 -0.326665  0.258441  ...  0.155142 -0.102439 -0.397522  0.243152   \n",
              "2 -0.271889  0.058019 -0.155045  ...  0.131858  0.011409 -0.455784  0.259496   \n",
              "3  0.115359 -0.056955  0.055758  ...  0.202641 -0.280212 -0.013400 -0.075353   \n",
              "4 -0.259864  0.326355  0.022939  ...  0.216391  0.242005 -0.092364  0.298605   \n",
              "\n",
              "         26        27        28        29        30        31  \n",
              "0 -0.269220  0.191771 -0.094684  0.178524 -0.136390 -0.050486  \n",
              "1 -0.167941 -0.025723  0.069258 -0.024735  0.018322 -0.180069  \n",
              "2 -0.146869  0.145466  0.276061  0.004051 -0.088571 -0.169602  \n",
              "3 -0.076547  0.002127  0.124289  0.016724  0.285925  0.128968  \n",
              "4 -0.110453  0.108763  0.228472 -0.106571  0.071141 -0.012153  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# DEBUG / PREVIEW — inspect saved CSV\n",
        "\n",
        "pd.read_csv(\"outputs.csv\").head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzcL4t7268rG"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doSNlwQB4rdG"
      },
      "source": [
        "## Phase 4: Semantic Evaluation (Linear Probe & Visualization)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6JIPt_E5LqK"
      },
      "source": [
        "# **Load embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdmZjtI35FH4",
        "outputId": "c559620a-0399-4f02-e88d-fb6034f67813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 700\n",
            "Embedding dimension: 32\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"outputs.csv\")\n",
        "\n",
        "audio_ids = df.iloc[:, 0].values\n",
        "embeddings = df.iloc[:, 1:].values\n",
        "\n",
        "print(\"Total samples:\", embeddings.shape[0])\n",
        "print(\"Embedding dimension:\", embeddings.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JvKyh535gVK"
      },
      "source": [
        "# **Cosine similarity retrieval**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRdG_cLj5SMc",
        "outputId": "7c87a1d6-26f3-4580-a8f0-6d8836024152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query audio: 000002.mp3\n",
            "\n",
            "Top 5 similar audios:\n",
            "006448.mp3 -> similarity: 0.646\n",
            "006802.mp3 -> similarity: 0.59\n",
            "007376.mp3 -> similarity: 0.587\n",
            "006440.mp3 -> similarity: 0.536\n",
            "006609.mp3 -> similarity: 0.512\n"
          ]
        }
      ],
      "source": [
        "# EXPLORATORY / DEMO — cosine similarity check (not formal evaluation)\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# pick a query\n",
        "query_idx = 0\n",
        "query_embedding = embeddings[query_idx].reshape(1, -1)\n",
        "\n",
        "# compute similarity\n",
        "similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
        "\n",
        "# top-5 most similar (excluding itself)\n",
        "top_k = similarities.argsort()[::-1][1:6]\n",
        "\n",
        "print(\"Query audio:\", audio_ids[query_idx])\n",
        "print(\"\\nTop 5 similar audios:\")\n",
        "for idx in top_k:\n",
        "    print(audio_ids[idx], \"-> similarity:\", round(similarities[idx], 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC4x6x6a60Bv"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 5: Bonus / Extensions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvVL2CCT85Js"
      },
      "source": [
        "# **GRANDMASTER EXTENSIONS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXMgAl7G7dHP"
      },
      "source": [
        "## Qualitative Retrieval Demonstration\n",
        "\n",
        "**Expected behavior**:\n",
        "*   Similar audio tracks cluster closer\n",
        "*   Noise-augmented versions remain nearby\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCvCRlcS9N-4"
      },
      "source": [
        "## Stability & Robustness\n",
        "\n",
        "The model was trained using contrastive self-supervised learning\n",
        "with additive noise and feature masking.\n",
        "\n",
        "**This encourages invariance to:**\n",
        "\n",
        "*   Background noise\n",
        "*   Minor spectral corruption\n",
        "*   Recording variations\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11 (impulse_env)",
      "language": "python",
      "name": "impulse_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
