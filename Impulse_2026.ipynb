{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5PbW3Xvrc5I"
      },
      "source": [
        "# EchoFind – Self-Supervised Audio Representation Learning\n",
        "Impulse 2026 Submission (Cleaned Pipeline)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 1: Input Pipeline & Preprocessing (Steps 1–4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kZ3iN6Mhx72",
        "outputId": "9d03e8e4-b0fc-4976-a853-8a5bbf9ed811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiVTnFM0ie5d",
        "outputId": "21c912f5-ef72-44f9-88ed-6719ed79e4b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Safe base created at: /content/drive/MyDrive/Impulse2026_SSL/data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "SAFE_BASE = \"/content/drive/MyDrive/Impulse2026_SSL\"\n",
        "DATA_DIR = f\"{SAFE_BASE}/data\"\n",
        "\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Safe base created at:\", DATA_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yCwmqHPjFP5",
        "outputId": "3b3e0e53-c91b-4e85-878e-81c0ae2721f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exists: True\n",
            "Sample folders: ['000', '001', '002', '003', '004']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "SAFE_AUDIO_PATH = f\"{DATA_DIR}/fma_small/fma_small\"\n",
        "print(\"Exists:\", os.path.exists(SAFE_AUDIO_PATH))\n",
        "print(\"Sample folders:\", sorted(os.listdir(SAFE_AUDIO_PATH))[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgkGOhRKjMmg",
        "outputId": "19c9bf86-0a3e-4ce1-8d79-5469bc6b4141"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LOCKED audio root: /content/drive/MyDrive/Impulse2026_SSL/data/fma_small/fma_small\n"
          ]
        }
      ],
      "source": [
        "audio_root = SAFE_AUDIO_PATH\n",
        "print(\"LOCKED audio root:\", audio_root)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 2: Self-Supervised Representation Learning (Steps 5–12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoYXPTgkj8dv"
      },
      "source": [
        "# **Step-5 MFCC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnTJ46gukCJL",
        "outputId": "8451e27a-a30a-485f-bb6f-829b3a89e77e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MFCC shape: (40, 1291)\n"
          ]
        }
      ],
      "source": [
        "# FEATURE EXTRACTION DEMO — MFCC on single sample (for understanding)\n",
        "import librosa\n",
        "\n",
        "mfcc = librosa.feature.mfcc(\n",
        "    y=signal,\n",
        "    sr=sr,\n",
        "    n_mfcc=40\n",
        ")\n",
        "\n",
        "print(\"MFCC shape:\", mfcc.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd5vnn_TkZo_"
      },
      "source": [
        "# **STEP 6 — Convert variable-length MFCC → fixed-size embedding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cFOlZxYkcfg",
        "outputId": "e1212ca7-063a-48a2-d960-04e0b608c3cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MFCC original shape: (40, 1291)\n",
            "After mean pooling: (40,)\n"
          ]
        }
      ],
      "source": [
        "# DEMO — explaining MFCC → fixed-size via mean pooling (single sample)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "mfcc_mean = np.mean(mfcc, axis=1)\n",
        "\n",
        "print(\"MFCC original shape:\", mfcc.shape)\n",
        "print(\"After mean pooling:\", mfcc_mean.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u26kquXElOVo",
        "outputId": "c22dcc7b-3017-4f48-fa98-9f1f206f67f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final embedding shape: (80,)\n"
          ]
        }
      ],
      "source": [
        "# DEMO — constructing fixed-length embedding (mean + std)\n",
        "\n",
        "mfcc_std = np.std(mfcc, axis=1)\n",
        "\n",
        "embedding = np.concatenate([mfcc_mean, mfcc_std])\n",
        "\n",
        "print(\"Final embedding shape:\", embedding.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJWaso_flWNo"
      },
      "source": [
        "# **STEP 7 — Apply this embedding extraction to MULTIPLE audio files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQGA9X38lcKk"
      },
      "outputs": [],
      "source": [
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def extract_embedding(audio_path, sr=22050, n_mfcc=40):\n",
        "    signal, _ = librosa.load(audio_path, sr=sr)\n",
        "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "    mfcc_mean = np.mean(mfcc, axis=1)\n",
        "    mfcc_std = np.std(mfcc, axis=1)\n",
        "\n",
        "    embedding = np.concatenate([mfcc_mean, mfcc_std])\n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN4N52H6lzPl",
        "outputId": "a6f2d8b4-9e2e-4a9e-9e4a-cf88af532825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total audio files found: 8000\n",
            "Sample file: /content/drive/MyDrive/Impulse2026_SSL/data/fma_small/fma_small/000/000002.mp3\n"
          ]
        }
      ],
      "source": [
        "audio_files = []\n",
        "\n",
        "for folder in sorted(os.listdir(BASE_AUDIO_PATH)):\n",
        "    folder_path = os.path.join(BASE_AUDIO_PATH, folder)\n",
        "\n",
        "    if not os.path.isdir(folder_path):\n",
        "        continue\n",
        "\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith(\".mp3\"):\n",
        "            audio_files.append(os.path.join(folder_path, file))\n",
        "\n",
        "print(\"Total audio files found:\", len(audio_files))\n",
        "print(\"Sample file:\", audio_files[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPKC3Vvpl5HL"
      },
      "outputs": [],
      "source": [
        "# SUBSAMPLING FOR SPEED — not required for final pipeline\n",
        "\n",
        "sample_files = audio_files[:1291]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFdcrgWumTQP",
        "outputId": "db9f041b-1d62-4a62-9c78-c6e9ba4b16a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding matrix shape: (1291, 80)\n",
            "Mean: 4.094213\n",
            "Std: 26.30422\n"
          ]
        }
      ],
      "source": [
        "\n",
        "embeddings = []\n",
        "\n",
        "for path in sample_files:\n",
        "    emb = extract_embedding(path)\n",
        "    embeddings.append(emb)\n",
        "\n",
        "X = np.array(embeddings)\n",
        "\n",
        "print(\"Embedding matrix shape:\", X.shape)\n",
        "print(\"Mean:\", X.mean())\n",
        "print(\"Std:\", X.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1LJtrZPqzP6"
      },
      "source": [
        "# **STEP 8 — Normalize the embedding matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42b5l0ZjrBVC",
        "outputId": "681b9bc0-1ff0-466a-cccc-d40b1d963a8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (1291, 80)\n",
            "Mean: 5.9096783e-10\n",
            "Std: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "embedding_matrix = X   # LOCK THIS\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_norm = scaler.fit_transform(embedding_matrix)\n",
        "\n",
        "print(\"Shape:\", X_norm.shape)\n",
        "print(\"Mean:\", np.mean(X_norm))\n",
        "print(\"Std:\", np.std(X_norm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs3hV96etrbe"
      },
      "source": [
        "# **STEP 9 — SSL AUGMENTATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "5eaU1Go8tvzC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def augment_embedding(x, noise_std=0.1, drop_prob=0.07):\n",
        "    x_aug = x.copy()\n",
        "    x_aug += np.random.normal(0, noise_std, size=x.shape)\n",
        "    mask = np.random.rand(*x.shape) > drop_prob\n",
        "    x_aug *= mask\n",
        "    return x_aug\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chvN9E6UwM-A"
      },
      "source": [
        "# **STEP 10 — Define the Neural Encoder (MLP)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "laR4t_h8wPPK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "cZT6OojIwa-d"
      },
      "outputs": [],
      "source": [
        "class AudioEncoder(nn.Module):\n",
        "    def __init__(self, input_dim=80, hidden_dim=128, output_dim=32):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.net(x)\n",
        "        z = F.normalize(z, dim=1)  # critical for cosine-based SSL\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5qy15upwh7D",
        "outputId": "a097e0fc-8434-4606-bac4-8017e044e646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AudioEncoder(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=80, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=32, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AudioEncoder().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1KzA2JnwyrM"
      },
      "source": [
        "# **STEP 11 — Define the Contrastive Loss (SSL Learning Signal)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Cj4oNH5xw1D-"
      },
      "outputs": [],
      "source": [
        "def contrastive_loss(z1, z2, temperature=0.1):\n",
        "    \"\"\"\n",
        "    z1, z2: (batch_size, embedding_dim)\n",
        "    \"\"\"\n",
        "    batch_size = z1.size(0)\n",
        "\n",
        "    # Similarity matrix\n",
        "    sim_matrix = torch.matmul(z1, z2.T) / temperature\n",
        "\n",
        "    # Positive pairs are on the diagonal\n",
        "    labels = torch.arange(batch_size).to(z1.device)\n",
        "\n",
        "    loss = F.cross_entropy(sim_matrix, labels)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krfvQwHLx3AX"
      },
      "source": [
        "# **STEP 12 — Full SSL Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "t2Dv6lj1x6RO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SSLAudioDataset(Dataset):\n",
        "    def __init__(self, X):\n",
        "        self.X = X\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx]\n",
        "        x1 = augment_embedding(x)\n",
        "        x2 = augment_embedding(x)\n",
        "        return (\n",
        "            torch.tensor(x1, dtype=torch.float32),\n",
        "            torch.tensor(x2, dtype=torch.float32)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frb2sqWxzrog",
        "outputId": "dc9037fc-c98b-4977-de24-d950ebf61001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batches per epoch: 40\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset = SSLAudioDataset(X_norm)\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "print(\"Batches per epoch:\", len(dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "TZ_wGJMEz3Ha"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndIGq9xCz7v6",
        "outputId": "db75daed-c5b0-4a22-8d6e-c7331d6f088e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/15] - Avg Loss: 0.1955\n",
            "Epoch [2/15] - Avg Loss: 0.0755\n",
            "Epoch [3/15] - Avg Loss: 0.0600\n",
            "Epoch [4/15] - Avg Loss: 0.0528\n",
            "Epoch [5/15] - Avg Loss: 0.0519\n",
            "Epoch [6/15] - Avg Loss: 0.0515\n",
            "Epoch [7/15] - Avg Loss: 0.0429\n",
            "Epoch [8/15] - Avg Loss: 0.0415\n",
            "Epoch [9/15] - Avg Loss: 0.0413\n",
            "Epoch [10/15] - Avg Loss: 0.0355\n",
            "Epoch [11/15] - Avg Loss: 0.0366\n",
            "Epoch [12/15] - Avg Loss: 0.0369\n",
            "Epoch [13/15] - Avg Loss: 0.0338\n",
            "Epoch [14/15] - Avg Loss: 0.0302\n",
            "Epoch [15/15] - Avg Loss: 0.0325\n"
          ]
        }
      ],
      "source": [
        "epochs = 15\n",
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for x1, x2 in dataloader:\n",
        "        x1 = x1.to(device)\n",
        "        x2 = x2.to(device)\n",
        "\n",
        "        z1 = model(x1)\n",
        "        z2 = model(x2)\n",
        "\n",
        "        loss = contrastive_loss(z1, z2)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] - Avg Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyFcx646Hu2M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# CHECKPOINT SAVE — trained encoder (path is environment-specific)\n",
        "# CHECKPOINT 1 — end of Phase 2\n",
        "output_dir = \"/content/drive/MyDrive/Impulse2026/weights\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "torch.save(\n",
        "    model.state_dict(),\n",
        "    os.path.join(output_dir, \"encoder_final.pth\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M3ShOxkJ2H-"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 3: Retrieval / Shazam Test (Steps 12.5–14)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag_h9Nj6Ii6a"
      },
      "source": [
        "# **STEP 12.5 — Phase 3: Retrieval (Shazam Test)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeO8nfepIpYS",
        "outputId": "c454f35d-d52e-4434-ce1e-aff1be42e5cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper function `get_audio_model_embedding` defined.\n"
          ]
        }
      ],
      "source": [
        "#Loaded Trained Encoder\n",
        "model.load_state_dict(torch.load(\n",
        "    \"/content/drive/MyDrive/Impulse2026/weights/encoder_final.pth\"\n",
        "))\n",
        "model.eval()\n",
        "\n",
        "def get_audio_model_embedding(audio_path, model, scaler_obj, device_obj):\n",
        "    # 1. Extract raw MFCC embedding\n",
        "    raw_embedding = extract_embedding(audio_path)\n",
        "\n",
        "    # 2. Normalize using the trained scaler\n",
        "    normalized_embedding = scaler_obj.transform(raw_embedding.reshape(1, -1))\n",
        "\n",
        "    # 3. Pass through the trained model\n",
        "    model.eval() # Ensure model is in evaluation mode\n",
        "    with torch.no_grad():\n",
        "        tensor_embedding = torch.tensor(normalized_embedding, dtype=torch.float32).to(device_obj)\n",
        "        final_embedding = model(tensor_embedding).cpu().numpy().flatten()\n",
        "    return final_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkEIVcPVJmml",
        "outputId": "808ce2a4-00c8-4125-b038-5d63101a599b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Re-populating database with model-generated embeddings...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Building model embedding database: 100%|██████████| 200/200 [00:38<00:00,  5.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Database re-populated with 200 model embeddings, shape of first: (32,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# SUBSAMPLING FOR SPEED — limit database size\n",
        "\n",
        "torch.save(\n",
        "    database,\n",
        "    \"/content/drive/MyDrive/Impulse2026/weights/database_embeddings.pt\"\n",
        ")\n",
        "audio_files_phase3 = audio_files[:200]\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Re-populate the database with model-generated embeddings\n",
        "print(\"Re-populating database with model-generated embeddings...\")\n",
        "database_model_embeddings = {}\n",
        "model.eval() # Ensure model is in eval mode for inference\n",
        "\n",
        "# audio_files_phase3 is already defined in mQEcKLrxVZ7l\n",
        "for path in tqdm(audio_files_phase3, desc=\"Building model embedding database\"):\n",
        "    track_id = os.path.basename(path)\n",
        "    # Use global scaler and device, which are assumed to be available after previous cells' execution\n",
        "    model_emb = get_audio_model_embedding(path, model, scaler, device)\n",
        "    database_model_embeddings[track_id] = model_emb\n",
        "\n",
        "# Overwrite the old database with the new one\n",
        "database = database_model_embeddings\n",
        "print(f\"Database re-populated with {len(database)} model embeddings, shape of first: {next(iter(database.values())).shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "jalrRl-fWhAv"
      },
      "outputs": [],
      "source": [
        "#retrival Function\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def predict_track(query_audio_path, model, database_embeddings_dict):\n",
        "\n",
        "    query_model_embedding = get_audio_model_embedding(query_audio_path, model, scaler, device)\n",
        "    best_id, best_score = None, -1.0\n",
        "\n",
        "    for track_id, db_model_embedding in database_embeddings_dict.items():\n",
        "\n",
        "        score = cosine_similarity(query_model_embedding.reshape(1, -1), db_model_embedding.reshape(1, -1))[0][0]\n",
        "        if score > best_score:\n",
        "            best_score, best_id = score, track_id\n",
        "\n",
        "    return best_id, best_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76qn8LKf0IPu"
      },
      "source": [
        "# **STEP 13 — Generate FINAL Learned Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "HqBETiNr0K2y"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLv3JaJ20QYW",
        "outputId": "1a615446-bbb1-4fa2-afde-e7ef562850a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final embedding matrix shape: (1291, 32)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "final_embeddings = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(X_norm), 32):\n",
        "        batch = torch.tensor(\n",
        "            X_norm[i:i+32],\n",
        "            dtype=torch.float32\n",
        "        ).to(device)\n",
        "\n",
        "        z = model(batch)\n",
        "        final_embeddings.append(z.cpu().numpy())\n",
        "\n",
        "final_embeddings = np.vstack(final_embeddings)\n",
        "\n",
        "print(\"Final embedding matrix shape:\", final_embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqOPp9tY13Hc"
      },
      "source": [
        "# **STEP - 14 OUTPUT CSV- download**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5Uoz2uG2r8Z",
        "outputId": "2f0c31e6-6050-4b1b-8936-25fca18813d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "outputs.csv saved with shape: (1291, 33)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "df = pd.DataFrame(final_embeddings)\n",
        "df.insert(0, \"audio_id\", audio_ids)\n",
        "\n",
        "df.to_csv(\"outputs.csv\", index=False)\n",
        "print(\"outputs.csv saved with shape:\", df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "Dk74NrUa2swf",
        "outputId": "b74b1157-acc2-46e5-a6f4-9a2441c575b5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2ccd8f61-30b1-4697-96de-9603c5138103\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_id</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000002.mp3</td>\n",
              "      <td>-0.134546</td>\n",
              "      <td>-0.203144</td>\n",
              "      <td>-0.112648</td>\n",
              "      <td>-0.165240</td>\n",
              "      <td>0.198168</td>\n",
              "      <td>0.025838</td>\n",
              "      <td>0.287654</td>\n",
              "      <td>-0.028808</td>\n",
              "      <td>-0.050204</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090983</td>\n",
              "      <td>0.317081</td>\n",
              "      <td>0.251757</td>\n",
              "      <td>-0.012939</td>\n",
              "      <td>-0.211842</td>\n",
              "      <td>-0.126510</td>\n",
              "      <td>-0.129348</td>\n",
              "      <td>-0.483498</td>\n",
              "      <td>0.018453</td>\n",
              "      <td>-0.114290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000005.mp3</td>\n",
              "      <td>-0.079768</td>\n",
              "      <td>0.061186</td>\n",
              "      <td>0.150750</td>\n",
              "      <td>-0.287016</td>\n",
              "      <td>0.183859</td>\n",
              "      <td>0.076505</td>\n",
              "      <td>0.108031</td>\n",
              "      <td>0.211313</td>\n",
              "      <td>0.034009</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.317580</td>\n",
              "      <td>0.427251</td>\n",
              "      <td>-0.109436</td>\n",
              "      <td>-0.206771</td>\n",
              "      <td>-0.109308</td>\n",
              "      <td>-0.262877</td>\n",
              "      <td>0.112738</td>\n",
              "      <td>-0.184598</td>\n",
              "      <td>0.230005</td>\n",
              "      <td>-0.157471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000010.mp3</td>\n",
              "      <td>-0.012335</td>\n",
              "      <td>-0.102070</td>\n",
              "      <td>-0.077606</td>\n",
              "      <td>0.098091</td>\n",
              "      <td>0.304376</td>\n",
              "      <td>0.166140</td>\n",
              "      <td>-0.016884</td>\n",
              "      <td>0.219623</td>\n",
              "      <td>-0.332840</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.070334</td>\n",
              "      <td>-0.004720</td>\n",
              "      <td>-0.057896</td>\n",
              "      <td>-0.187673</td>\n",
              "      <td>-0.072459</td>\n",
              "      <td>-0.037344</td>\n",
              "      <td>0.205653</td>\n",
              "      <td>0.094696</td>\n",
              "      <td>-0.394854</td>\n",
              "      <td>0.152230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000140.mp3</td>\n",
              "      <td>-0.053597</td>\n",
              "      <td>0.236146</td>\n",
              "      <td>0.161285</td>\n",
              "      <td>-0.194873</td>\n",
              "      <td>-0.260485</td>\n",
              "      <td>0.066552</td>\n",
              "      <td>0.129362</td>\n",
              "      <td>0.428730</td>\n",
              "      <td>-0.173821</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.047097</td>\n",
              "      <td>0.027309</td>\n",
              "      <td>0.087803</td>\n",
              "      <td>-0.008124</td>\n",
              "      <td>0.044391</td>\n",
              "      <td>-0.110676</td>\n",
              "      <td>-0.209026</td>\n",
              "      <td>0.229265</td>\n",
              "      <td>0.079742</td>\n",
              "      <td>0.256740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000141.mp3</td>\n",
              "      <td>0.080411</td>\n",
              "      <td>0.277191</td>\n",
              "      <td>0.012166</td>\n",
              "      <td>-0.165974</td>\n",
              "      <td>-0.111288</td>\n",
              "      <td>-0.214607</td>\n",
              "      <td>0.172267</td>\n",
              "      <td>0.050671</td>\n",
              "      <td>0.091603</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054698</td>\n",
              "      <td>-0.367172</td>\n",
              "      <td>-0.083327</td>\n",
              "      <td>-0.299882</td>\n",
              "      <td>0.101643</td>\n",
              "      <td>0.160854</td>\n",
              "      <td>0.007950</td>\n",
              "      <td>-0.190199</td>\n",
              "      <td>-0.150482</td>\n",
              "      <td>-0.019141</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ccd8f61-30b1-4697-96de-9603c5138103')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ccd8f61-30b1-4697-96de-9603c5138103 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ccd8f61-30b1-4697-96de-9603c5138103');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     audio_id         0         1         2         3         4         5  \\\n",
              "0  000002.mp3 -0.134546 -0.203144 -0.112648 -0.165240  0.198168  0.025838   \n",
              "1  000005.mp3 -0.079768  0.061186  0.150750 -0.287016  0.183859  0.076505   \n",
              "2  000010.mp3 -0.012335 -0.102070 -0.077606  0.098091  0.304376  0.166140   \n",
              "3  000140.mp3 -0.053597  0.236146  0.161285 -0.194873 -0.260485  0.066552   \n",
              "4  000141.mp3  0.080411  0.277191  0.012166 -0.165974 -0.111288 -0.214607   \n",
              "\n",
              "          6         7         8  ...        22        23        24        25  \\\n",
              "0  0.287654 -0.028808 -0.050204  ... -0.090983  0.317081  0.251757 -0.012939   \n",
              "1  0.108031  0.211313  0.034009  ... -0.317580  0.427251 -0.109436 -0.206771   \n",
              "2 -0.016884  0.219623 -0.332840  ... -0.070334 -0.004720 -0.057896 -0.187673   \n",
              "3  0.129362  0.428730 -0.173821  ... -0.047097  0.027309  0.087803 -0.008124   \n",
              "4  0.172267  0.050671  0.091603  ... -0.054698 -0.367172 -0.083327 -0.299882   \n",
              "\n",
              "         26        27        28        29        30        31  \n",
              "0 -0.211842 -0.126510 -0.129348 -0.483498  0.018453 -0.114290  \n",
              "1 -0.109308 -0.262877  0.112738 -0.184598  0.230005 -0.157471  \n",
              "2 -0.072459 -0.037344  0.205653  0.094696 -0.394854  0.152230  \n",
              "3  0.044391 -0.110676 -0.209026  0.229265  0.079742  0.256740  \n",
              "4  0.101643  0.160854  0.007950 -0.190199 -0.150482 -0.019141  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# DEBUG / PREVIEW — inspect saved CSV\n",
        "\n",
        "pd.read_csv(\"outputs.csv\").head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzcL4t7268rG"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doSNlwQB4rdG"
      },
      "source": [
        "## Phase 4: Semantic Evaluation (Linear Probe & Visualization)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6JIPt_E5LqK"
      },
      "source": [
        "# **Load embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdmZjtI35FH4",
        "outputId": "c559620a-0399-4f02-e88d-fb6034f67813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 1291\n",
            "Embedding dimension: 32\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"outputs.csv\")\n",
        "\n",
        "audio_ids = df.iloc[:, 0].values\n",
        "embeddings = df.iloc[:, 1:].values\n",
        "\n",
        "print(\"Total samples:\", embeddings.shape[0])\n",
        "print(\"Embedding dimension:\", embeddings.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JvKyh535gVK"
      },
      "source": [
        "# **Cosine similarity retrieval**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRdG_cLj5SMc",
        "outputId": "7c87a1d6-26f3-4580-a8f0-6d8836024152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query audio: 000002.mp3\n",
            "\n",
            "Top 5 similar audios:\n",
            "026902.mp3 -> similarity: 0.655\n",
            "024701.mp3 -> similarity: 0.646\n",
            "020469.mp3 -> similarity: 0.644\n",
            "015476.mp3 -> similarity: 0.623\n",
            "019729.mp3 -> similarity: 0.596\n"
          ]
        }
      ],
      "source": [
        "# EXPLORATORY / DEMO — cosine similarity check (not formal evaluation)\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# pick a query\n",
        "query_idx = 0\n",
        "query_embedding = embeddings[query_idx].reshape(1, -1)\n",
        "\n",
        "# compute similarity\n",
        "similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
        "\n",
        "# top-5 most similar (excluding itself)\n",
        "top_k = similarities.argsort()[::-1][1:6]\n",
        "\n",
        "print(\"Query audio:\", audio_ids[query_idx])\n",
        "print(\"\\nTop 5 similar audios:\")\n",
        "for idx in top_k:\n",
        "    print(audio_ids[idx], \"-> similarity:\", round(similarities[idx], 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC4x6x6a60Bv"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 5: Bonus / Extensions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvVL2CCT85Js"
      },
      "source": [
        "# **GRANDMASTER EXTENSIONS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXMgAl7G7dHP"
      },
      "source": [
        "## Qualitative Retrieval Demonstration\n",
        "\n",
        "**Expected behavior**:\n",
        "*   Similar audio tracks cluster closer\n",
        "*   Noise-augmented versions remain nearby\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCvCRlcS9N-4"
      },
      "source": [
        "## Stability & Robustness\n",
        "\n",
        "The model was trained using contrastive self-supervised learning\n",
        "with additive noise and feature masking.\n",
        "\n",
        "**This encourages invariance to:**\n",
        "\n",
        "*   Background noise\n",
        "*   Minor spectral corruption\n",
        "*   Recording variations\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
